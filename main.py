import streamlit as st
from gradio_client import Client
import time

# Inicializar idioma (solo interfaz)
idioma = st.sidebar.selectbox("ğŸŒ Idioma / Language / Llengua", ("EspaÃ±ol", "CatalÃ ", "English"))

# Traducciones de la interfaz
tÃ­tulo = {
    "EspaÃ±ol": "AREStudio AI - Asistente conversacional",
    "CatalÃ ": "AREStudio AI - Assistent conversacional",
    "English": "AREStudio AI - Conversational Assistant"
}

subtÃ­tulo = {
    "EspaÃ±ol": "Hazme preguntas y hablarÃ© contigo como un asistente inteligente.",
    "CatalÃ ": "Fes-me preguntes i parlarÃ© amb tu com un assistent intelÂ·ligent.",
    "English": "Ask me anything and Iâ€™ll talk with you like a smart assistant."
}

# Mostrar UI
st.title(tÃ­tulo[idioma])
st.caption(subtÃ­tulo[idioma])

# Cliente Gradio
client = Client("VIDraft/Gemma-3-R1984-27B")

# Inicializar historial en estado de sesiÃ³n
if "mensajes" not in st.session_state:
    st.session_state.mensajes = []

# Mostrar historial
for msg in st.session_state.mensajes:
    with st.chat_message(msg["rol"]):
        st.markdown(msg["contenido"])

# Entrada del usuario
pregunta = st.chat_input("ğŸ’¬ Escribe aquÃ­...")

if pregunta:
    st.session_state.mensajes.append({"rol": "user", "contenido": pregunta})
    with st.chat_message("user"):
        st.markdown(pregunta)

    with st.chat_message("assistant"):
        pensando = st.empty()
        pensando.markdown("â³ Pensando...")
        try:
            respuesta = client.predict(pregunta, api_name="/chat")
        except Exception as e:
            respuesta = "âš ï¸ OcurriÃ³ un error al contactar con el modelo."

        pensando.markdown(respuesta)
    st.session_state.mensajes.append({"rol": "assistant", "contenido": respuesta})
