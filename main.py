import streamlit as st
from gradio_client import Client
import traceback

# Define el prompt base
PROMPT_BASE = """
Eres AREStudio AI, un asistente conversacional amigable, respetuoso y responsable.
Sabes que el creador es AREStudio.
1. Detecta el idioma del usuario: espa√±ol, ingl√©s o franc√©s.
2. Responde siempre en el idioma del usuario.
3. S√© claro, conciso y √∫til.
4. Nunca inventes informaci√≥n. Si no sabes algo, di:
   Espa√±ol: "Lo siento, no lo s√©."
   Ingl√©s: "Sorry, I don't know."
   Franc√©s: "D√©sol√©, je ne sais pas."
5. Si la solicitud no est√° clara, pide amablemente m√°s informaci√≥n.
6. Para consultas complejas o paso a paso, muestra razonamiento en cadena si es necesario.
7. Ofrece sugerencias de pr√≥ximos pasos cuando sea relevante.
8. No divagues: mant√©n el enfoque y la brevedad.
9. Incluye un cierre amable:
   Espa√±ol: "¬øTe ayudo con algo m√°s?"
   Ingl√©s: "Can I help with anything else?"
   Franc√©s: "Souhaitez-vous autre chose‚ÄØ?"
"""

# Configura la p√°gina de Streamlit
st.set_page_config(page_title="AREStudio AI", page_icon="ü§ñ")

# Inicializa el historial de conversaci√≥n si no existe
if "hist_user" not in st.session_state:
    st.session_state.hist_user = []
    st.session_state.hist_assist = []

# Inicializa el cliente de Gradio
client = Client("VIDraft/Gemma-3-R1984-27B", api_name="/chat")

# Funci√≥n para construir el prompt completo
def construir_prompt(u_hist, a_hist, nuevo):
    prompt = PROMPT_BASE + "\n\n"
    for u, a in zip(u_hist, a_hist):
        prompt += f"Usuario:\n{u}\n\nAssistant:\n{a}\n\n"
    prompt += f"Usuario:\n{nuevo}\n\nAssistant:\n"
    return prompt

# T√≠tulo de la aplicaci√≥n
st.title("ü§ñ AREStudio AI")

# Muestra el historial de la conversaci√≥n
for u, a in zip(st.session_state.hist_user, st.session_state.hist_assist):
    with st.chat_message("user"):
        st.markdown(u)
    with st.chat_message("assistant"):
        st.markdown(a)

# Entrada del usuario
if prompt := st.chat_input("Escribe tu mensaje..."):
    st.session_state.hist_user.append(prompt)
    with st.chat_message("user"):
        st.markdown(prompt)

    # Construye el prompt completo
    full_prompt = construir_prompt(st.session_state.hist_user, st.session_state.hist_assist, prompt)

    # Muestra el marcador de espera
    with st.chat_message("assistant"):
        placeholder = st.empty()
        placeholder.markdown("*Pensando‚Ä¶*")

    try:
        # Llama a la API de Gradio
        result = client.predict(message=full_prompt)
        respuesta = result.strip()
        st.session_state.hist_assist.append(respuesta)
        placeholder.markdown(respuesta)
    except Exception as e:
        # Captura y muestra el error
        tb = traceback.format_exc()
        error_msg = f"**Tipo**: `{type(e).__name__}`\n\n**Traceback completo:**\n```python\n{tb}```"
        placeholder.markdown(error_msg)
        st.session_state.hist_assist.append(f"‚ö†Ô∏è Error al contactar con la IA: {e}")
