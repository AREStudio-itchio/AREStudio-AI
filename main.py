import streamlit as st
from gradio_client import Client
import traceback

# Configuraci√≥n de p√°gina
st.set_page_config(
    page_title="AREStudio AI",
    page_icon="https://img.itch.zone/aW1nLzIyMjkyNTc3LnBuZw==/315x250%23c/CeYE7v.png"
)

# Inicializar cliente Gradio
client = Client("VIDraft/Gemma-3-R1984-27B")

# Estado inicial de la sesi√≥n
if "user_messages" not in st.session_state:
    st.session_state.user_messages = []
if "assistant_responses" not in st.session_state:
    st.session_state.assistant_responses = []
if "last_language" not in st.session_state:
    st.session_state.last_language = "en"

# Funci√≥n para detectar idioma
def detectar_idioma(texto):
    texto = texto.lower()
    if any(palabra in texto for palabra in ["qu√©", "c√≥mo", "gracias", "hola"]):
        return "es"
    elif any(palabra in texto for palabra in ["bonjour", "merci", "comment", "salut"]):
        return "fr"
    elif any(palabra in texto for palabra in ["hello", "thanks", "please", "what", "how"]):
        return "en"
    return "en"

# Funci√≥n para construir el prompt completo
def construir_prompt(usuario, asistente, idioma):
    instrucciones = {
        "es": (
            "Act√∫a como un asistente AI llamado AREStudio AI. "
            "Eres respetuoso, claro, amable, y √∫til. No inventes informaci√≥n. "
            "Responde siempre en espa√±ol."
        ),
        "en": (
            "Act as an AI assistant named AREStudio AI. "
            "You are respectful, clear, kind, and helpful. Do not make up information. "
            "Always reply in English."
        ),
        "fr": (
            "Agis comme un assistant IA nomm√© AREStudio AI. "
            "Tu es respectueux, clair, aimable et utile. Ne pas inventer d'informations. "
            "R√©ponds toujours en fran√ßais."
        )
    }

    prompt = f"{instrucciones[idioma]}\n\n"
    for u, a in zip(usuario, asistente):
        prompt += f"Usuario:\n{u}\n\nAsistente:\n{a}\n\n"

    # Si hay un mensaje pendiente sin respuesta
    if len(usuario) > len(asistente):
        prompt += f"Usuario:\n{usuario[-1]}\n\nAsistente:\n"

    return prompt

# UI
st.title("ü§ñ AREStudio AI")
st.markdown(
    "Tu asistente creado por [AREStudio](https://arestudio.itch.io) ‚Äî amable, respetuoso, responsable y ahora con favicon üé®"
)

# Mostrar historial
for user_msg, assistant_msg in zip(st.session_state.user_messages, st.session_state.assistant_responses):
    with st.chat_message("user"):
        st.markdown(user_msg)
    with st.chat_message("assistant"):
        st.markdown(assistant_msg)

# Si el √∫ltimo mensaje no tiene respuesta a√∫n
if len(st.session_state.user_messages) > len(st.session_state.assistant_responses):
    with st.chat_message("user"):
        st.markdown(st.session_state.user_messages[-1])

# Entrada de usuario
user_input = st.chat_input("Escribe tu mensaje...")

if user_input:
    st.session_state.user_messages.append(user_input)
    idioma = detectar_idioma(user_input)
    st.session_state.last_language = idioma

    # Construcci√≥n del prompt
    prompt = construir_prompt(
        st.session_state.user_messages,
        st.session_state.assistant_responses,
        idioma
    )

    try:
        # Predicci√≥n del modelo
        respuesta = client.predict(
            prompt,
            max_new_tokens=1000,
            api_name="/chat"
        )

        respuesta_limpia = respuesta.strip()
        st.session_state.assistant_responses.append(respuesta_limpia)
        with st.chat_message("assistant"):
            st.markdown(respuesta_limpia)

    except Exception as e:
        tb = traceback.format_exc()
        error_msg = (
            f"‚ö†Ô∏è **Error al contactar con AREStudio AI:**\n\n"
            f"**Tipo:** `{type(e).__name__}`\n"
            f"**Mensaje:** `{e}`\n\n"
            f"**Traceback:**\n```python\n{tb}```"
        )
        st.session_state.assistant_responses.append(error_msg)
        with st.chat_message("assistant"):
            st.error(error_msg)
